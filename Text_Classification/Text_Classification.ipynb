{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eGA5YxF97E3"
   },
   "source": [
    "# Text Classification using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRjQi9nP-CdA"
   },
   "source": [
    "## Import Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 1965,
     "status": "ok",
     "timestamp": 1688730069309,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "xNRer4Oz-Mxd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQyhj3jX-Oqk"
   },
   "source": [
    "## Dataset characteristics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15306,
     "status": "ok",
     "timestamp": 1688730084612,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "UAPTE5Jj-RdK",
    "outputId": "e2d40749-a263-49ac-e7c0-5304c3e8a647"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset properties on train section:\n",
      "\t Number of training data points: 1178\n",
      "\t Number of test data points: 785\n",
      "\t Number of Classes: 2\n",
      "\t Class names:  ['comp.graphics', 'sci.med']\n"
     ]
    }
   ],
   "source": [
    "categories = ['comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=False, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "    categories=categories, shuffle=False, random_state=42)\n",
    "\n",
    "print(\"Dataset properties on train section:\")\n",
    "print(\"\\t Number of training data points: %d\" % len(twenty_train.data))\n",
    "print(\"\\t Number of test data points: %d\" % len(twenty_test.data))\n",
    "print(\"\\t Number of Classes: %d\" % len(categories))\n",
    "print(\"\\t Class names: \" ,(twenty_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3BTn8wybzH5"
   },
   "source": [
    "## A sample of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1688730084613,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "qV74xmOgcabl",
    "outputId": "613a816d-a1a6-4a5c-fa64-36284fec7962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Why isolate it?\n",
      "From: chinsz@eis.calstate.edu (Christopher Hinsz)\n",
      "Organization: Calif State Univ/Electronic Information Services\n",
      "Lines: 13\n",
      "\n",
      "\tDoes anyone on this newsgroup happen to know WHY morphine was\n",
      "first isolated from opium?  If you know why, or have an idea for where I\n",
      "could look to find this info, please mail me.\n",
      "\tCSH\n",
      "any suggestionas would be greatly appreciated\n",
      "\n",
      "--\n",
      " \"Kilimanjaro is a pretty tricky climb. Most of it's up, until you reach\n",
      "the very, very top, and then it tends to slope away rather sharply.\"\n",
      "\t\t\t\t\tSir George Head, OBE (JC)\n",
      "------------------------------------------------------------------------------\n",
      "LOGIC: \"The point is frozen, the beast is dead, what is the difference?\"\n",
      "\t\t\t\t\tGavin Millarrrrrrrrrr (JC)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyRQrlhMccdq"
   },
   "source": [
    "the category name of the instance can be found as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1688730084613,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "YQXuwz5ickAM",
    "outputId": "0e266f91-7fc5-4600-ac4b-54e66bf93907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "sci.med\n",
      "0\n",
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target[0])\n",
    "print(twenty_train.target_names[twenty_train.target[0]])\n",
    "\n",
    "# print another different example\n",
    "print(twenty_train.target[2])\n",
    "print(twenty_train.target_names[twenty_train.target[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRriwdBkD2lb"
   },
   "source": [
    "some notes about the above two functions\n",
    "* twenty_train.target[0]\n",
    "    * input: index of data point\n",
    "    * output 0 or 1\n",
    "    * 0 --> sci.med class\n",
    "    * 1 --> comp.graphics class\n",
    "\n",
    "twenty_train.target_names[twenty_train.target[0]]\n",
    "the name of the class that the data point belongs to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTuJXmgQdkYK"
   },
   "source": [
    "print the class names of the first 10 data examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1688730084615,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "Nr-57YnMeIpp",
    "outputId": "8af54917-35e3-4651-a6f7-5c529d0d39e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sci.med\n",
      "sci.med\n",
      "comp.graphics\n",
      "sci.med\n",
      "comp.graphics\n",
      "sci.med\n",
      "sci.med\n",
      "comp.graphics\n",
      "sci.med\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "for t in twenty_train.target[:10]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9av39ipneTYl"
   },
   "source": [
    "## Feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1673,
     "status": "ok",
     "timestamp": 1688730086283,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "jXpFn4Anh-bF",
    "outputId": "02d27b6d-c510-4b9d-d52f-8e0c79386cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1178, 24614)\n",
      "(785, 24614)\n"
     ]
    }
   ],
   "source": [
    "# bag of words\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\n",
    "# Normalize\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "print(X_train_tf.shape)\n",
    "print(X_test_tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTGDzuZzmhPo"
   },
   "source": [
    "## Document classification using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3166,
     "status": "ok",
     "timestamp": 1688730089446,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "5fjQ9krzDLUD",
    "outputId": "0f770c70-f811-4681-e13a-06bdd8809f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data is 89.4267515923567%.\n"
     ]
    }
   ],
   "source": [
    "clf = SVC().fit(X_train_tf, twenty_train.target)\n",
    "\n",
    "preds = clf.predict(X_test_tf)\n",
    "\n",
    "accuracy = np.mean(preds == twenty_test.target)\n",
    "print(f'Accuracy on test data is {accuracy*100}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHnhp3fOFogO"
   },
   "source": [
    "Try some real text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1688730089447,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "l3M08-3iFl3y",
    "outputId": "7844eb8b-ef6d-437e-9dd0-d7be0661f246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'OpenGL on the GPU is fast' => comp.graphics\n",
      "'Doctor takes care of patients' => sci.med\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['OpenGL on the GPU is fast', 'Doctor takes care of patients']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUh3XYBfg3E6"
   },
   "source": [
    "## Naive Bayes with Bernoulli\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqO9qtvw_B-s"
   },
   "source": [
    "In this task, we want to train a naive bayes classifier with bernoulli features.\n",
    "\n",
    "As the first step, let us convert all features to binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1688730089447,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "gEfLGRXkBj6p",
    "outputId": "20d6e09c-e710-4ba2-a8b1-83a4de144734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1178, 24614)\n",
      "(785, 24614)\n"
     ]
    }
   ],
   "source": [
    "X_train_b = X_train_tf.sign()\n",
    "X_test_b = X_test_tf.sign()\n",
    "# if x == 0  --> 0\n",
    "# if x > 0   --> 1\n",
    "print(X_train_b.shape); print(X_test_b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1688730089447,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "9Ttp1uGP6gKo",
    "outputId": "eb5cb2e3-4b19-4663-e2cb-44153c199ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 360\n"
     ]
    }
   ],
   "source": [
    "# how to loop over non-zero values\n",
    "for i, j in zip(*X_train_b.nonzero()):\n",
    "    print(i, j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7wMtxE5B2hz"
   },
   "source": [
    "### Using MLE\n",
    "\n",
    "Some Naive Bayes notations:  \n",
    "For each data point $(x,y)$\n",
    "* $x = [x_1 , x_2 ⋯ x_d]$ and $x_i \\in \\{0,1\\}$\n",
    "* $y \\in \\{0,1\\}$\n",
    "\n",
    "\n",
    "Naive bayes assumes that the features are independent given the class label:\n",
    "\n",
    "* $P(x|y=0)= \\Pi \\ P(x_i|y=0)$\n",
    "* $P(x|y=1)= \\Pi \\ P(x_i|y=1)$\n",
    "\n",
    "The set of parameters of the classifier are denoted by $θ=\\{α, β, γ\\}$. The parameters are defined by\n",
    "\n",
    "* $α=[α_1, α_2, ..., α_d]$\n",
    "* $α_i=P(x_i=1|y=0, θ)$ $(i \\in \\{1 \\cdots d\\})$\n",
    "\n",
    "---\n",
    "\n",
    "* $β=[β_1, β_2, ..., β_d]$\n",
    "* $β_i=P(x_i=1|y=1, θ)$ $(i \\in \\{1 \\cdots d\\})$\n",
    "\n",
    "---\n",
    "\n",
    "* $γ = P(y=0|θ)$\n",
    "\n",
    "After using MLE calculation, the following are the parameters:\n",
    "* Let $n_0$ be the number of data examples with label 0\n",
    "* Let $n_1$ be the number of data examples with label 1\n",
    "---\n",
    "* $\\alpha_j = \\frac{\\underset{i:y^i=0}{\\sum} x^i_j}{n_0}$\n",
    "---\n",
    "* $\\beta_j = \\frac{\\underset{i:y^i=1}{\\sum} x^i_j}{n_1}$\n",
    "---\n",
    "* $\\gamma = \\frac{n_0}{n_0 + n_1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1688730089879,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "O2xGRlmozra6"
   },
   "outputs": [],
   "source": [
    "# get different sizes\n",
    "trainSetSize = X_train_b.shape[0]\n",
    "testSetSize = X_test_b.shape[0]\n",
    "featureSize = X_train_b.shape[1]\n",
    "\n",
    "# calculate n0 and n1\n",
    "class0Index = [] ; class1Index = []\n",
    "for i in range(trainSetSize):\n",
    "    if(twenty_train.target[i] == 0):\n",
    "        class0Index.append(i)\n",
    "    else:\n",
    "        class1Index.append(i)\n",
    "n0 = len(class0Index) ; n1 = len(class1Index)\n",
    "\n",
    "\n",
    "# get a feature dictionary --> This is essentially a hashmap\n",
    "# key represents feature index\n",
    "# value is a list containing document index that contains this feature\n",
    "documentNonZero = X_train_b.nonzero()[0]\n",
    "featureNonZero = X_train_b.nonzero()[1]\n",
    "featureDict = {}\n",
    "for i in range(featureSize):\n",
    "    featureDict[i] = []\n",
    "\n",
    "for i in range(len(featureNonZero)):\n",
    "    featureDict[featureNonZero[i]].append(documentNonZero[i])\n",
    "\n",
    "#calculate alpha_i\n",
    "def getSingleAlphaML(featureIndex):\n",
    "    sum = 0;\n",
    "    documents = featureDict[featureIndex]\n",
    "    for document in documents:\n",
    "        if (twenty_train.target[document] == 0):\n",
    "            sum += X_train_b[document , featureIndex]\n",
    "    return sum / n0\n",
    "\n",
    "\n",
    "#calculate beta_i\n",
    "def getSingleBetaML(featureIndex):\n",
    "    sum = 0;\n",
    "    documents = featureDict[featureIndex]\n",
    "    for document in documents:\n",
    "        if (twenty_train.target[document] == 1):\n",
    "            sum += X_train_b[document , featureIndex]\n",
    "    return sum / n1\n",
    "\n",
    "\n",
    "def estimate_alpha_with_mle():\n",
    "  # Derive expression of alpha value with MLE.\n",
    "  # alpha = P(x_i=1|y=0, theta)\n",
    "    alpha = []\n",
    "    for i in range(featureSize):\n",
    "        alpha.append(getSingleAlphaML(i) )\n",
    "    return alpha\n",
    "\n",
    "def estimate_beta_with_mle():\n",
    "  # Derive expression of beta value with MLE\n",
    "  # beta = P(x_i=1|y=1, theta)\n",
    "\n",
    "    beta = []\n",
    "    for i in range(featureSize):\n",
    "        beta.append(getSingleBetaML(i) )\n",
    "\n",
    "    return beta\n",
    "\n",
    "def estimate_gamma_with_mle():\n",
    "  # Derive expression of gamma value with MLE\n",
    "  # gamma = P(y=0|theta)\n",
    "    return n0 / (n0 + n1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4727,
     "status": "ok",
     "timestamp": 1688730094604,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "PajSl0x2MFG9",
    "outputId": "f951f0f8-1a83-4fa5-dfcc-7d9d0aeb801b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma is 0.49575551782682514\n",
      "beta is [0.03198653198653199, 0.03198653198653199, 0.0016835016835016834, 0.003367003367003367, 0.0, 0.0, 0.0016835016835016834, 0.0, 0.0, 0.0016835016835016834]\n",
      "alpha is [0.03424657534246575, 0.018835616438356163, 0.0, 0.0, 0.0017123287671232876, 0.0017123287671232876, 0.0, 0.0017123287671232876, 0.0017123287671232876, 0.0]\n"
     ]
    }
   ],
   "source": [
    "gamma = estimate_gamma_with_mle()\n",
    "beta = estimate_beta_with_mle()\n",
    "alpha = estimate_alpha_with_mle()\n",
    "\n",
    "print(f'gamma is {gamma}')\n",
    "print(f'beta is {beta[:10]}')\n",
    "print(f'alpha is {alpha[:10]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcKNDtP9JrcB"
   },
   "source": [
    "Classifier\n",
    "\n",
    "$p(y=1|x, \\theta) = \\frac{p(y=1,x,\\theta)}{p(x,\\theta)} = \\frac{p(x|y=1,\\theta)*p(y=1|\\theta)*p(\\theta)}{p(x,\\theta)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1688730094604,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "kPJzMyDbKoaV"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import random\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, gamma, alpha, beta) -> None:\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def getLabel(self, C1P, C0P):\n",
    "        if (C1P > C0P):\n",
    "            return 1\n",
    "        if (C0P > C1P):\n",
    "            return 0\n",
    "        if ( self.gamma > 0.5):\n",
    "            return 0\n",
    "        if (( 1 - self.gamma > 0.5)):\n",
    "            return 1\n",
    "        return random.choice([0 , 1])\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        dataSetSize = X.shape[0]\n",
    "        featureSize = X.shape[1]\n",
    "        predictions = []\n",
    "        \n",
    "        # change to numpy array\n",
    "        X = X.toarray()\n",
    "        for i in range(dataSetSize):\n",
    "            class0Prob = self.gamma\n",
    "            class1Prob = 1 - self.gamma\n",
    "            for j in range(featureSize):\n",
    "                if(X[i , j] == 1):\n",
    "                    class0Prob *= self.alpha[j]\n",
    "                    class1Prob *= self.beta[j]\n",
    "                else:\n",
    "                    class0Prob *= (1 - self.alpha[j])\n",
    "                    class1Prob *= (1 - self.beta[j])\n",
    "            label = self.getLabel(class1Prob, class0Prob)\n",
    "            predictions.append(label)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFBjpJy9KuVk"
   },
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50095,
     "status": "ok",
     "timestamp": 1688730144682,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "loM34Os_mIsD",
    "outputId": "4b9af1cb-7ac7-4086-e739-390297a57d2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Set(using MLE): 96.01018675721562 %\n",
      "Accuracy on Testing  Set(using MLE): 62.54777070063694 %\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayes(gamma, alpha, beta)\n",
    "\n",
    "TrainSetPredictions = classifier.predict(X_train_b)\n",
    "TestSetPredictions = classifier.predict(X_test_b)\n",
    "\n",
    "\n",
    "trainSetSize = X_train_b.shape[0]\n",
    "correctCount = 0\n",
    "for i in range(trainSetSize):\n",
    "    if (TrainSetPredictions[i] == twenty_train.target[i]):\n",
    "        correctCount += 1\n",
    "trainSetAccuracy = correctCount / trainSetSize\n",
    "\n",
    "\n",
    "testSetSize = X_test_b.shape[0]\n",
    "correctCount = 0\n",
    "for i in range(testSetSize):\n",
    "    if(TestSetPredictions[i] == twenty_test.target[i]):\n",
    "        correctCount += 1\n",
    "testSetAccuracy = correctCount / testSetSize\n",
    "\n",
    "print(\"Accuracy on Training Set(using MLE): \" + str(trainSetAccuracy * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using MLE): \" + str(testSetAccuracy * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7xPj720d5Ud"
   },
   "source": [
    "### Using MAP\n",
    "\n",
    "* $P(θ) = P(γ).(∏P(α_i)).(∏P(β_i))$\n",
    "* $P(γ=a)=P(α_1=a)=P(α_2=a)=...=P(β_1=a)=P(β_2=a)=....=f(a)$\n",
    "    * If $a <= 0.5$ then $f(a) = 4a$\n",
    "    * If $a > 0.5$ then $f(a) = 4 - 4a$\n",
    "\n",
    "After calculation:\n",
    "* If $\\alpha_j \\leq 0.5$, $\\alpha_j = \\frac{\\left(\\underset{i:y^i=0}{\\sum} x^i_j \\right) + 1}{n_0 + 1}$\n",
    "---\n",
    "* If $\\alpha_j > 0.5$, $\\alpha_j = \\frac{\\underset{i:y^i=0}{\\sum} x^i_j}{n_0 + 1}$\n",
    "---\n",
    "* If $\\beta_j \\leq 0.5$, $\\beta_j = \\frac{\\left( \\underset{i:y^i=1}{\\sum} x^i_j \\right) + 1}{n_1 + 1}$\n",
    "---\n",
    "* If $\\beta_j > 0.5$, $\\beta_j = \\frac{ \\underset{i:y^i=1}{\\sum} x^i_j }{n_1 + 1}$\n",
    "---\n",
    "* If $\\gamma \\leq 0.5$, $\\gamma = \\frac{n_0 + 1}{n_0 + n_1 + 1}$\n",
    "---\n",
    "* If $\\gamma > 0.5$, $\\gamma = \\frac{n_0}{n_0 + n_1 + 1}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1688730144682,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "CZX3H8JtgupS"
   },
   "outputs": [],
   "source": [
    "#calculate alpha_i\n",
    "def getSingleAlphaMAP(featureIndex):\n",
    "    sum = 0;\n",
    "    documents = featureDict[featureIndex]\n",
    "    for document in documents:\n",
    "        if (twenty_train.target[document] == 0):\n",
    "            sum += X_train_b[document , featureIndex]\n",
    "    if ((sum / n0) <= 0.5):\n",
    "        return (sum + 1) / (n0 +1)\n",
    "    return sum / (n0 + 1)\n",
    "\n",
    "\n",
    "#calculate beta_i\n",
    "def getSingleBetaMAP(featureIndex):\n",
    "    sum = 0;\n",
    "    documents = featureDict[featureIndex]\n",
    "    for document in documents:\n",
    "        if (twenty_train.target[document] == 1):\n",
    "            sum += X_train_b[document , featureIndex]\n",
    "    if ((sum / n1) <= 0.5):\n",
    "        return (sum + 1) / (n1 + 1)\n",
    "    return sum / (n1 + 1)\n",
    "\n",
    "\n",
    "def estimate_alpha_with_map():\n",
    "  # Derive expression of alpha value with MAP.\n",
    "  # alpha = P(x_i=1|y=0, theta)\n",
    "    alpha = []\n",
    "    for i in range(featureSize):\n",
    "        alpha.append(getSingleAlphaMAP(i) )\n",
    "    return alpha\n",
    "\n",
    "\n",
    "def estimate_beta_with_map():\n",
    "  # Derive expression of beta value with MAP\n",
    "  # beta = P(x_i=1|y=1, theta)\n",
    "    beta = []\n",
    "    for i in range(featureSize):\n",
    "        beta.append(getSingleBetaMAP(i) )\n",
    "    return beta\n",
    "\n",
    "def estimate_gamma_with_map():\n",
    "  # Derive expression of gamma value with MAP\n",
    "  # gamma = P(y=0|theta)\n",
    "    temp = n0 / (n0 + n1)\n",
    "    if (temp <= 0.5):\n",
    "        return (n0 + 1) / (n0 + n1 + 1)\n",
    "    return n0 / (n0 + n1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4862,
     "status": "ok",
     "timestamp": 1688730149525,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "rT58zyafjkoW",
    "outputId": "93fac54d-632d-417f-9088-0c048e1eacee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma is 0.4961832061068702\n",
      "beta is [0.03361344537815126, 0.03361344537815126, 0.0033613445378151263, 0.005042016806722689, 0.0016806722689075631, 0.0016806722689075631, 0.0033613445378151263, 0.0016806722689075631, 0.0016806722689075631, 0.0033613445378151263]\n",
      "alpha is [0.035897435897435895, 0.020512820512820513, 0.0017094017094017094, 0.0017094017094017094, 0.003418803418803419, 0.003418803418803419, 0.0017094017094017094, 0.003418803418803419, 0.003418803418803419, 0.0017094017094017094]\n"
     ]
    }
   ],
   "source": [
    "gamma = estimate_gamma_with_map()\n",
    "beta = estimate_beta_with_map()\n",
    "alpha = estimate_alpha_with_map()\n",
    "\n",
    "print(f'gamma is {gamma}')\n",
    "print(f'beta is {beta[:10]}')\n",
    "print(f'alpha is {alpha[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52361,
     "status": "ok",
     "timestamp": 1688730201868,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "6q1BWXbcmGYh",
    "outputId": "381a2575-d76d-4086-eabe-d9d4114409a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Set(using MAP): 88.96434634974533 %\n",
      "Accuracy on Testing  Set(using MAP): 75.54140127388536 %\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayes(gamma, alpha, beta)\n",
    "TrainSetPredictions = classifier.predict(X_train_b)\n",
    "TestSetPredictions = classifier.predict(X_test_b)\n",
    "\n",
    "\n",
    "trainSetSize = X_train_b.shape[0]\n",
    "correctCount = 0\n",
    "for i in range(trainSetSize):\n",
    "    if (TrainSetPredictions[i] == twenty_train.target[i]):\n",
    "        correctCount += 1\n",
    "trainSetAccuracy = correctCount / trainSetSize\n",
    "\n",
    "\n",
    "testSetSize = X_test_b.shape[0]\n",
    "correctCount = 0\n",
    "for i in range(testSetSize):\n",
    "    if(TestSetPredictions[i] == twenty_test.target[i]):\n",
    "        correctCount += 1\n",
    "testSetAccuracy = correctCount / testSetSize\n",
    "\n",
    "print(\"Accuracy on Training Set(using MAP): \" + str(trainSetAccuracy * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using MAP): \" + str(testSetAccuracy * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmKxpf6xf5i9"
   },
   "source": [
    "\n",
    "For accuracy on training set, MLE performs better than MAP. MLE has accuracy of 96.01% on training set and MAP has accuracy of 88.96% on training set.\n",
    "However, when it comes to testing dataset, MAP(with accuracy of 75.54%)\n",
    "performed better than MLE(with accuracy of 62.55%). Clearly, MLE method caused overfitting problem.\\\n",
    "\\\n",
    "Justification:\n",
    "1. For MLE, parameters estimations only base on the dataset we have. It\n",
    "has no knowledge about the distribution of the parameters. As a result,\n",
    "MLE cannot generalize the model we are developing so that MLE caused\n",
    "overfitting problem.\n",
    "2. For MAP, we can avoid 0 values in $α_i$ and $β_i$. If $α_i$ and $β_i$\n",
    "calculated from MLE are 0, then 1 will be added to the numerator when\n",
    "calculating MAP $α_i$ and $β_i$ so that 0 values are avoided in $α_i$ and\n",
    "$β_i$ for MAP. Therefore, we can avoid 0 probability values when we do the\n",
    "predictions, which can make predictions more meaningful. As a result,\n",
    "accuracy improved for testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf3fSX2fpPb1"
   },
   "source": [
    "## SVM Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1688730202449,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "Q8iKxrB5Aam0"
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "    categories=categories, shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test',\n",
    "    categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oo7Uv7R3Sg85"
   },
   "source": [
    "### Using Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16390,
     "status": "ok",
     "timestamp": 1688730218835,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "5kdMUnzxPx6S",
    "outputId": "e21706a8-9d55-4872-e2be-ce541623e9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Set(using SVM linear kernel): 98.49357554275588 %\n",
      "Accuracy on Testing  Set(using SVM linaer kernel): 88.08255659121171 %\n"
     ]
    }
   ],
   "source": [
    "# using CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\n",
    "# using TFIDF\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "# train SVC\n",
    "clf = SVC(kernel = 'linear').fit(X_train_tf, twenty_train.target)\n",
    "\n",
    "# do predictions\n",
    "trainpreds = clf.predict(X_train_tf)\n",
    "testpreds = clf.predict(X_test_tf)\n",
    "\n",
    "def getAccuracy(Yhat , Y):\n",
    "    dataSize = len(Y)\n",
    "    correctCount = 0\n",
    "    for i in range(dataSize):\n",
    "        if(Yhat[i] == Y[i]):\n",
    "            correctCount += 1\n",
    "    return correctCount / dataSize\n",
    "\n",
    "\n",
    "TrainA = getAccuracy(trainpreds , twenty_train.target)\n",
    "TestA = getAccuracy(testpreds , twenty_test.target)\n",
    "\n",
    "print(\"Accuracy on Training Set(using SVM linear kernel): \" + str(TrainA * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using SVM linaer kernel): \" + str(TestA * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMhwckdqrj_p"
   },
   "source": [
    "### Using RBF kernel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57504,
     "status": "ok",
     "timestamp": 1688730276320,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "47znPqTusfEp",
    "outputId": "ddc5cdf7-de8b-40d9-db3f-585f922b1b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Set(using SVM RBF kernel with gamma = 0.70): 98.93664155959237 %\n",
      "Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.70): 86.21837549933421 %\n",
      "\n",
      "Accuracy on Training Set(using SVM RBF kernel with gamma = 0.65): 98.84802835622509 %\n",
      "Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.65): 86.08521970705726 %\n",
      "\n",
      "Accuracy on Training Set(using SVM RBF kernel with gamma = 0.60): 98.58218874612317 %\n",
      "Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.60): 85.9520639147803 %\n"
     ]
    }
   ],
   "source": [
    "clf70 = SVC(kernel = 'rbf' , gamma = 0.70).fit(X_train_tf, twenty_train.target)\n",
    "clf65 = SVC(kernel = 'rbf' , gamma = 0.65).fit(X_train_tf, twenty_train.target)\n",
    "clf60 = SVC(kernel = 'rbf' , gamma = 0.60).fit(X_train_tf, twenty_train.target)\n",
    "\n",
    "trainpreds70 = clf70.predict(X_train_tf)\n",
    "testpreds70 = clf70.predict(X_test_tf)\n",
    "\n",
    "trainpreds65 = clf65.predict(X_train_tf)\n",
    "testpreds65 = clf65.predict(X_test_tf)\n",
    "\n",
    "trainpreds60 = clf60.predict(X_train_tf)\n",
    "testpreds60 = clf60.predict(X_test_tf)\n",
    "\n",
    "TrainA70 = getAccuracy(trainpreds70 , twenty_train.target)\n",
    "TestA70 = getAccuracy(testpreds70 , twenty_test.target)\n",
    "\n",
    "TrainA65 = getAccuracy(trainpreds65 , twenty_train.target)\n",
    "TestA65 = getAccuracy(testpreds65 , twenty_test.target)\n",
    "\n",
    "TrainA60 = getAccuracy(trainpreds60 , twenty_train.target)\n",
    "TestA60 = getAccuracy(testpreds60 , twenty_test.target)\n",
    "\n",
    "print(\"Accuracy on Training Set(using SVM RBF kernel with gamma = 0.70): \" + str(TrainA70 * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.70): \" + str(TestA70 * 100) + \" %\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Accuracy on Training Set(using SVM RBF kernel with gamma = 0.65): \" + str(TrainA65 * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.65): \" + str(TestA65 * 100) + \" %\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Accuracy on Training Set(using SVM RBF kernel with gamma = 0.60): \" + str(TrainA60 * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.60): \" + str(TestA60 * 100) + \" %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGI7gVl82Old"
   },
   "source": [
    "Discussion for different gamma values:\\\n",
    "RBF kernel is used to measure the similarity between two points. Smaller gamma value means further influence. As a result, two points can be considered similar even if they are quite far from each other. This is not desirable for classification problem. As a consequence, smaller gamma value produces worse accuracy for classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GY2q_ofZsiyz"
   },
   "source": [
    "### Using IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71365,
     "status": "ok",
     "timestamp": 1688730347664,
     "user": {
      "displayName": "Tingyu Shi",
      "userId": "07980525302904059213"
     },
     "user_tz": -480
    },
    "id": "TTOaRmZmyTfo",
    "outputId": "7b754643-29ce-4490-d8e9-0d52b5df499d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Training Set(using SVM RBF kernel with gamma = 0.70 idf=True): 99.9113867966327 %\n",
      "Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.70 idf=True): 90.0133155792277 %\n",
      "\n",
      "Accuracy on Training Set(using SVM RBF kernel with gamma = 0.65 idf=True): 99.9113867966327 %\n",
      "Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.65 idf=True): 90.14647137150466 %\n",
      "\n",
      "Accuracy on Training Set(using SVM RBF kernel with gamma = 0.60 idf=True): 99.9113867966327 %\n",
      "Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.60 idf=True): 90.21304926764314 %\n"
     ]
    }
   ],
   "source": [
    "# using CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_test_counts = count_vect.transform(twenty_test.data)\n",
    "\n",
    "# using TFIDF\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_test_tf = tf_transformer.transform(X_test_counts)\n",
    "\n",
    "clf70 = SVC(kernel = 'rbf' , gamma = 0.70).fit(X_train_tf, twenty_train.target)\n",
    "clf65 = SVC(kernel = 'rbf' , gamma = 0.65).fit(X_train_tf, twenty_train.target)\n",
    "clf60 = SVC(kernel = 'rbf' , gamma = 0.60).fit(X_train_tf, twenty_train.target)\n",
    "\n",
    "trainpreds70 = clf70.predict(X_train_tf)\n",
    "testpreds70 = clf70.predict(X_test_tf)\n",
    "\n",
    "trainpreds65 = clf65.predict(X_train_tf)\n",
    "testpreds65 = clf65.predict(X_test_tf)\n",
    "\n",
    "trainpreds60 = clf60.predict(X_train_tf)\n",
    "testpreds60 = clf60.predict(X_test_tf)\n",
    "\n",
    "TrainA70 = getAccuracy(trainpreds70 , twenty_train.target)\n",
    "TestA70 = getAccuracy(testpreds70 , twenty_test.target)\n",
    "\n",
    "TrainA65 = getAccuracy(trainpreds65 , twenty_train.target)\n",
    "TestA65 = getAccuracy(testpreds65 , twenty_test.target)\n",
    "\n",
    "TrainA60 = getAccuracy(trainpreds60 , twenty_train.target)\n",
    "TestA60 = getAccuracy(testpreds60 , twenty_test.target)\n",
    "\n",
    "print(\"Accuracy on Training Set(using SVM RBF kernel with gamma = 0.70 idf=True): \" + str(TrainA70 * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.70 idf=True): \" + str(TestA70 * 100) + \" %\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Accuracy on Training Set(using SVM RBF kernel with gamma = 0.65 idf=True): \" + str(TrainA65 * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.65 idf=True): \" + str(TestA65 * 100) + \" %\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Accuracy on Training Set(using SVM RBF kernel with gamma = 0.60 idf=True): \" + str(TrainA60 * 100) + \" %\")\n",
    "print(\"Accuracy on Testing  Set(using SVM RBF kernel with gamma = 0.60 idf=True): \" + str(TestA60 * 100) + \" %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2j_vHYpFujO"
   },
   "source": [
    "Discussion of using idf:\\\n",
    "If we turn on use_idf, the accuracies have increased on both training set\n",
    "and testing for all three $γ$ values. Turning on use_idf can decrease the\n",
    "impact of frequent words such as \"is\", \"the\", etc. This can increase the impact of other more important features in disguise. As a result, accuracies on both training set and testing set have increased."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
